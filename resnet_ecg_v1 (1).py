# -*- coding: utf-8 -*-
"""resnet_ecg_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AnWNvgNGZfqe47FhNeYJqkeMESAF2PeT
"""

import tensorflow as tf
tf.test.gpu_device_name()

import numpy as np
import pandas as pd
from keras import layers
from keras.layers import Input, Dense, Dropout, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Embedding, Add
from keras.layers import Conv1D, GlobalAveragePooling1D, AveragePooling2D, MaxPooling2D, MaxPool1D, ZeroPadding1D, GlobalMaxPooling2D, GlobalAveragePooling2D
from keras.models import Sequential, Model
from keras.utils import plot_model
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
from keras.layers.merge import concatenate
from sklearn.metrics import classification_report

mit_test_data = pd.read_csv('mitbih_test.csv', header=None)
mit_test_data = mit_test_data.sample(frac=1).reset_index(drop=True)

mit_train_data = pd.read_csv('mitbih_train.csv', header=None)
mit_train_data = mit_train_data.sample(frac=1).reset_index(drop=True)

ptbdb_abnormal_data = pd.read_csv('ptbdb_abnormal.csv', header=None)
ptbdb_normal_data = pd.read_csv('ptbdb_normal.csv', header=None)
ptb_both_data = [ptbdb_abnormal_data, ptbdb_normal_data]
ptb_all_data = pd.concat(ptb_both_data,keys=["abnormal","normal"])
random_boolean_array = np.random.rand(len(ptb_all_data)) < 0.8

train_ptb = ptb_all_data[random_boolean_array]
test_ptb = ptb_all_data[~random_boolean_array]

from keras.utils import to_categorical
mit_train_X, mit_train_y = mit_train_data.iloc[: , :-1], mit_train_data.iloc[: , -1]
mit_train_X, mit_val_X, mit_train_y, mit_val_y= train_test_split(mit_train_X,mit_train_y,test_size=0.2)
mit_test_X, mit_test_y = mit_test_data.iloc[: , :-1], mit_test_data.iloc[: , -1]
mit_train_y = to_categorical(mit_train_y)
mit_test_y = to_categorical(mit_test_y)
mit_val_y=to_categorical(mit_val_y)


ptb_train_X = train_ptb.loc[:, train_ptb.columns != 187]
ptb_train_y = train_ptb.loc[:, train_ptb.columns == 187]
ptb_train_y = to_categorical(ptb_train_y)
ptb_test_X = test_ptb.loc[:, test_ptb.columns != 187]
ptb_test_y = test_ptb.loc[:, test_ptb.columns == 187]
ptb_test_y = to_categorical(ptb_test_y)

print('N: ',len(mit_train_y[mit_train_y[:,0] == 1]))
print('S: ',len(mit_train_y[mit_train_y[:,1] == 1]))
print('V: ',len(mit_train_y[mit_train_y[:,2] == 1]))
print('F: ',len(mit_train_y[mit_train_y[:,3] == 1]))
print('Q: ',len(mit_train_y[mit_train_y[:,4] == 1]))

print('Normal: ',len(ptb_train_y[ptb_train_y[:,0] == 1]))
print('Abormal: ',len(ptb_train_y[ptb_train_y[:,1] == 1]))

print("mit_train_X shape:" , str(mit_train_X.shape))
print("mit_train_y shape:" , str(mit_train_y.shape))
print("mit_val_X shape:" , str(mit_val_X.shape))
print("mit_val_y shape:" , str(mit_val_y.shape))
print("mit_test_X shape:" , str(mit_test_X.shape))
print("mit_test_y shape:" , str(mit_test_y.shape))

print("ptb_train_X shape: ", str(ptb_train_X.shape) )
print("ptb_train_y shape:", str(ptb_train_y.shape) )
print("ptb_test_X shape", str(ptb_test_X.shape) )
print("ptb_test_y shape", str(ptb_test_y.shape) )

def residual_block(X, f, filters):
    F1, F2, F3 = filters

    X_shortcut = X

    X = Conv1D(filters = F1, kernel_size = 1, activation='relu', strides = 1, padding = 'valid')(X)
    X = BatchNormalization()(X)

    X = Conv1D(filters = F2, kernel_size = f, activation='relu', strides = 1, padding = 'same')(X)
    X = BatchNormalization()(X)

    X = Conv1D(filters = F3, kernel_size = 1, activation='relu', strides = 1, padding = 'valid')(X)
    X = BatchNormalization()(X)

    X = Add()([X,X_shortcut])
    X = Activation('relu')(X)

    return X

def convolutional_block(X, f, filters, s = 2):
    F1, F2, F3 = filters

    X_shortcut = X

    X = Conv1D(F1, 1, activation='relu', strides = s)(X)
    X = BatchNormalization()(X)

    X = Conv1D(F2, f, activation='relu', strides = 1,padding = 'same')(X)
    X = BatchNormalization()(X)

    X = Conv1D(F3, 1, strides = 1)(X)
    X = BatchNormalization()(X)

    X_shortcut = Conv1D(F3, 1, strides = s)(X_shortcut)
    X_shortcut = BatchNormalization()(X_shortcut)

    X = Add()([X,X_shortcut])
    X = Activation('relu')(X)

    return X

def create_resnet_model(num_classes, input_shape = (187,1), ):

    X_input = Input(input_shape)

    X = ZeroPadding1D(3)(X_input)

    X = Conv1D(64, 7, activation='relu', strides = 2)(X)
    X = BatchNormalization()(X)
    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)

    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)
    X = residual_block(X, 3, [64, 64, 256])
    X = residual_block(X, 3, [64, 64, 256])

    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)
    X = residual_block(X, 3, [128,128,512])
    X = residual_block(X, 3, [128,128,512])
    X = residual_block(X, 3, [128,128,512])

    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)
    X = residual_block(X, 3, [256, 256, 1024])
    X = residual_block(X, 3, [256, 256, 1024])
    X = residual_block(X, 3, [256, 256, 1024])
    X = residual_block(X, 3, [256, 256, 1024])
    X = residual_block(X, 3, [256, 256, 1024])

    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)
    X = residual_block(X, 3, [512, 512, 2048])
    X = residual_block(X, 3, [512, 512, 2048])

    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)

    X = Flatten()(X)
    X = Dense(num_classes,activation='softmax')(X)

    model = Model(inputs = X_input, outputs = X, name='ResNet')

    return model

"""Training and prediction using using MIT dataset"""

resNet_model_mit = create_resnet_model(5, input_shape = (187,1))

resNet_model_mit.summary()

plot_model(resNet_model_mit)

resNet_model_mit.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

resNet_model_history_mit = resNet_model_mit.fit(mit_train_X, mit_train_y, epochs = 20, batch_size = 100, validation_data = (mit_val_X, mit_val_y))

plt.plot(resNet_model_history_mit.history['accuracy'])
plt.plot(resNet_model_history_mit.history['val_accuracy'])
plt.legend(["accuracy","val_accuracy"])
plt.title('Training - MIT dataset')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

mit_pred_y = resNet_model_mit.predict(mit_test_X) # make prediction here
mit_predictions = []
for x in mit_pred_y:
  #print(x)
  most_conf_index = np.argmax(x)
  mit_predictions.append(most_conf_index)

mit_actual = []
for x in mit_test_y:
  #print(x)
  most_conf_index = np.argmax(x)
  mit_actual.append(most_conf_index)

from sklearn.metrics import accuracy_score
print(accuracy_score(mit_actual, mit_predictions))

mit_cf_matrix = confusion_matrix(mit_actual, mit_predictions)
print(mit_cf_matrix)
sns.heatmap(mit_cf_matrix/np.sum(mit_cf_matrix), annot=True,fmt='.3%', cmap='Blues')

print(classification_report(mit_actual,mit_predictions))

"""Training and prediction using ptb dataset"""

resNet_model_ptb = create_resnet_model(2, input_shape = (187,1))

resNet_model_ptb.summary()

plot_model(resNet_model_ptb)

resNet_model_ptb.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

resNet_model_history_ptb = resNet_model_ptb.fit(ptb_train_X, ptb_train_y, epochs = 20, batch_size = 100, validation_split=0.2)

plt.plot(resNet_model_history_ptb.history['accuracy'])
plt.plot(resNet_model_history_ptb.history['val_accuracy'])
plt.legend(["accuracy","val_accuracy"])
plt.title('Training - PTB dataset')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

ptb_pred_y = resNet_model_ptb.predict(ptb_test_X) # make prediction here
ptb_predictions = []
for x in ptb_pred_y:
  #print(x)
  most_conf_index = np.argmax(x)
  ptb_predictions.append(most_conf_index)

ptb_actual = []
for x in ptb_test_y:
  #print(x)
  most_conf_index = np.argmax(x)
  ptb_actual.append(most_conf_index)

from sklearn.metrics import accuracy_score
print(accuracy_score(ptb_actual, ptb_predictions))

ptb_cf_matrix = confusion_matrix(ptb_actual, ptb_predictions)
print(ptb_cf_matrix)
sns.heatmap(ptb_cf_matrix/np.sum(ptb_cf_matrix), annot=True,fmt='.3%', cmap='Blues')

print(classification_report(ptb_actual,ptb_predictions))